{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of Web Scraping captured and studied from <https://www.datacamp.com/community/tutorials/web-scraping-using-python> \n",
    "\n",
    "#Using Jupyter Notebook, you should start by importing the necessary modules (pandas, numpy, matplotlib.pyplot, seaborn). If you don't have Jupyter Notebook installed, I recommend installing it using the Anaconda Python distribution which is available on the internet. To easily display the plots, make sure to include the line %matplotlib inline as shown below.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform web scraping, you should also import the libraries shown below. The urllib.request module is used to open URLs. The Beautiful Soup package is used to extract data from html files. The Beautiful Soup library's name is bs4 which stands for Beautiful Soup, version 4.\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After importing necessary modules, you should specify the URL containing the dataset and pass it to urlopen() to get the html of the page.\n",
    "url = \"http://www.hubertiming.com/results/2017GPTR10K\"\n",
    "html = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the html of the page is just the first step. Next step is to create a Beautiful Soup object from the html. This is done by passing the html to the BeautifulSoup() function. The Beautiful Soup package is used to parse the html, that is, take the raw html text and break it into Python objects. The second argument 'lxml' is the html parser whose details you do not need to worry about at this point.\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "type(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Race results for the 2017 Intel Great Place to Run \\ Urban Clash Games!</title>\n"
     ]
    }
   ],
   "source": [
    "# The soup object allows you to extract interesting information about the website you're scraping such as getting the title of the page as shown below.\n",
    "# Get the title\n",
    "title = soup.title\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also get the text of the webpage and quickly print it out to check if it is what you expect.\n",
    "# Print out the text\n",
    "text = soup.get_text()\n",
    "#print(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"mailto:timing@hubertiming.com\">timing@hubertiming.com</a>,\n",
       " <a href=\"https://www.hubertiming.com/\">Huber Timing Home</a>,\n",
       " <a class=\"btn btn-primary btn-lg\" href=\"/results/2017GPTR\" role=\"button\" style=\"margin: 0px 0px 5px 5px\"><i aria-hidden=\"true\" class=\"fa fa-user\"></i> 5K Individual</a>,\n",
       " <a class=\"btn btn-primary btn-lg\" href=\"/results/team/2017GPTR\" role=\"button\" style=\"margin: 0px 0px 5px 5px\"><i aria-hidden=\"true\" class=\"fa fa-users\"></i> 5K Team</a>,\n",
       " <a class=\"btn btn-primary btn-lg\" href=\"/results/team/2017GPTR10K\" role=\"button\" style=\"margin: 0px 0px 5px 5px\"><i aria-hidden=\"true\" class=\"fa fa-users\"></i> 10K Team</a>,\n",
       " <a class=\"btn btn-primary btn-lg\" href=\"/results/summary/2017GPTR10K\" role=\"button\" style=\"margin: 0px 0px 5px 5px\"><i class=\"fa fa-stream\"></i> Summary</a>,\n",
       " <a id=\"individual\" name=\"individual\"></a>,\n",
       " <a data-url=\"/results/2017GPTR10K\" href=\"#tabs-1\" id=\"rootTab\" style=\"font-size: 18px\">10K Results</a>,\n",
       " <a href=\"https://www.hubertiming.com/\"><img height=\"65\" src=\"https://www.hubertiming.com//sites/all/themes/hubertiming/images/clockWithFinishSign_small.png\" width=\"50\"/>Huber Timing</a>,\n",
       " <a href=\"https://facebook.com/hubertiming/\"><img src=\"https://www.hubertiming.com/results/FB-f-Logo__blue_50.png\"/></a>,\n",
       " <a class=\"small\" id=\"bestFeatureEver\" style=\"color:#007bff\">Dark Mode</a>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use the find_all() method of soup to extract useful html tags within a webpage. Examples of useful tags include < a > for hyperlinks, < table > for tables, < tr > for table rows, < th > for table headers, and < td > for table cells. The code below shows how to extract all the hyperlinks within the webpage.\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mailto:timing@hubertiming.com\n",
      "https://www.hubertiming.com/\n",
      "/results/2017GPTR\n",
      "/results/team/2017GPTR\n",
      "/results/team/2017GPTR10K\n",
      "/results/summary/2017GPTR10K\n",
      "None\n",
      "#tabs-1\n",
      "https://www.hubertiming.com/\n",
      "https://facebook.com/hubertiming/\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# As you can see from the output above, html tags sometimes come with attributes such as class, src, etc. These attributes provide additional information about html elements. You can use a for loop and the get('\"href\") method to extract and print out only hyperlinks.\n",
    "all_links = soup.find_all(\"a\")\n",
    "for link in all_links:\n",
    "    print(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr colspan=\"2\">\n",
      "<b>10K:</b>\n",
      "</tr>, <tr>\n",
      "<td>Finishers:</td>\n",
      "<td>577</td>\n",
      "</tr>, <tr>\n",
      "<td>Male:</td>\n",
      "<td>414</td>\n",
      "</tr>, <tr>\n",
      "<td>Female:</td>\n",
      "<td>163</td>\n",
      "</tr>, <tr class=\"header\">\n",
      "<th>Place</th>\n",
      "<th>Bib</th>\n",
      "<th>Name</th>\n",
      "<th>Gender</th>\n",
      "<th>City</th>\n",
      "<th>State</th>\n",
      "<th>Chip Time</th>\n",
      "<th>Chip Pace</th>\n",
      "<th>Gun Time</th>\n",
      "<th>Team</th>\n",
      "</tr>, <tr data-bib=\"814\">\n",
      "<td>1</td>\n",
      "<td>814</td>\n",
      "<td>\r\n",
      "\r\n",
      "                    JARED WILSON\r\n",
      "\r\n",
      "                </td>\n",
      "<td>M</td>\n",
      "<td>TIGARD</td>\n",
      "<td>OR</td>\n",
      "<td>36:21</td>\n",
      "<td>5:51</td>\n",
      "<td>36:24</td>\n",
      "<td></td>\n",
      "</tr>, <tr data-bib=\"573\">\n",
      "<td>2</td>\n",
      "<td>573</td>\n",
      "<td>\r\n",
      "\r\n",
      "                    NATHAN A SUSTERSIC\r\n",
      "\r\n",
      "                </td>\n",
      "<td>M</td>\n",
      "<td>PORTLAND</td>\n",
      "<td>OR</td>\n",
      "<td>36:42</td>\n",
      "<td>5:55</td>\n",
      "<td>36:45</td>\n",
      "<td>\n",
      "<img class=\"lazy teamThumbs\" data-src=\"/teamLogoThumbnail/logo?teamName=INTEL%20TEAM%20F&amp;raceId=1251&amp;state=OR\"/>\r\n",
      "                            INTEL TEAM F\r\n",
      "                        </td>\n",
      "</tr>, <tr data-bib=\"687\">\n",
      "<td>3</td>\n",
      "<td>687</td>\n",
      "<td>\r\n",
      "\r\n",
      "                    FRANCISCO MAYA\r\n",
      "\r\n",
      "                </td>\n",
      "<td>M</td>\n",
      "<td>PORTLAND</td>\n",
      "<td>OR</td>\n",
      "<td>37:44</td>\n",
      "<td>6:05</td>\n",
      "<td>37:48</td>\n",
      "<td></td>\n",
      "</tr>, <tr data-bib=\"623\">\n",
      "<td>4</td>\n",
      "<td>623</td>\n",
      "<td>\r\n",
      "\r\n",
      "                    PAUL MORROW\r\n",
      "\r\n",
      "                </td>\n",
      "<td>M</td>\n",
      "<td>BEAVERTON</td>\n",
      "<td>OR</td>\n",
      "<td>38:34</td>\n",
      "<td>6:13</td>\n",
      "<td>38:37</td>\n",
      "<td></td>\n",
      "</tr>, <tr data-bib=\"569\">\n",
      "<td>5</td>\n",
      "<td>569</td>\n",
      "<td>\r\n",
      "\r\n",
      "                    DEREK G OSBORNE\r\n",
      "\r\n",
      "                </td>\n",
      "<td>M</td>\n",
      "<td>HILLSBORO</td>\n",
      "<td>OR</td>\n",
      "<td>39:21</td>\n",
      "<td>6:20</td>\n",
      "<td>39:24</td>\n",
      "<td>\n",
      "<img class=\"lazy teamThumbs\" data-src=\"/teamLogoThumbnail/logo?teamName=INTEL%20TEAM%20F&amp;raceId=1251&amp;state=OR\"/>\r\n",
      "                            INTEL TEAM F\r\n",
      "                        </td>\n",
      "</tr>]\n"
     ]
    }
   ],
   "source": [
    "# To print out table rows only, pass the 'tr' argument in soup.find_all().\n",
    "# Print the first 10 rows for sanity check\n",
    "rows = soup.find_all('tr')\n",
    "print(rows[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td>577</td>, <td>443</td>, <td>\r\n",
      "\r\n",
      "                    LIBBY B MITCHELL\r\n",
      "\r\n",
      "                </td>, <td>F</td>, <td>HILLSBORO</td>, <td>OR</td>, <td>1:41:18</td>, <td>16:20</td>, <td>1:42:10</td>, <td></td>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The goal of is to take a table from a webpage and convert it into a dataframe for easier manipulation using Python. To get there, you should get all table rows in list form first and then convert that list into a dataframe. Below is a for loop that iterates through table rows and prints out the cells of the rows.\n",
    "for row in rows:\n",
    "    row_td = row.find_all('td')\n",
    "print(row_td)\n",
    "type(row_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[577, 443, \r\n",
      "\r\n",
      "                    LIBBY B MITCHELL\r\n",
      "\r\n",
      "                , F, HILLSBORO, OR, 1:41:18, 16:20, 1:42:10, ]\n"
     ]
    }
   ],
   "source": [
    "# The output above shows that each row is printed with html tags embedded in each row. This is not what you want. You can use remove the html tags using Beautiful Soup or regular expressions.\n",
    "# The easiest way to remove html tags is to use Beautiful Soup, and it takes just one line of code to do this. Pass the string of interest into BeautifulSoup() and use the get_text() method to extract the text without html tags.\n",
    "str_cells = str(row_td)\n",
    "cleantext = BeautifulSoup(str_cells, \"lxml\").get_text()\n",
    "print(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[577, 443, \r\n",
      "\r\n",
      "                    LIBBY B MITCHELL\r\n",
      "\r\n",
      "                , F, HILLSBORO, OR, 1:41:18, 16:20, 1:42:10, ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using regular expressions is highly discouraged since it requires several lines of code and one can easily make mistakes. It requires importing the re (for regular expressions) module. The code below shows how to build a regular expression that finds all the characters inside the < td > html tags and replace them with an empty string for each table row. First, you compile a regular expression by passing a string to match to re.compile(). The dot, star, and question mark (.*?) will match an opening angle bracket followed by anything and followed by a closing angle bracket. It matches text in a non-greedy fashion, that is, it matches the shortest possible string. If you omit the question mark, it will match all the text between the first opening angle bracket and the last closing angle bracket. After compiling a regular expression, you can use the re.sub() method to find all the substrings where the regular expression matches and replace them with an empty string. The full code below generates an empty list, extract text in between html tags for each row, and append it to the assigned list.\n",
    "import re\n",
    "\n",
    "list_rows = []\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    str_cells = str(cells)\n",
    "    clean = re.compile('<.*?>')\n",
    "    clean2 = (re.sub(clean, '',str_cells))\n",
    "    list_rows.append(clean2)\n",
    "print(clean2)\n",
    "type(clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Finishers:, 577]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Male:, 414]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Female:, 163]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 814, \\r\\n\\r\\n                    JARED WIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2, 573, \\r\\n\\r\\n                    NATHAN A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[3, 687, \\r\\n\\r\\n                    FRANCISCO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[4, 623, \\r\\n\\r\\n                    PAUL MORR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[5, 569, \\r\\n\\r\\n                    DEREK G O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                                 []\n",
       "1                                  [Finishers:, 577]\n",
       "2                                       [Male:, 414]\n",
       "3                                     [Female:, 163]\n",
       "4                                                 []\n",
       "5  [1, 814, \\r\\n\\r\\n                    JARED WIL...\n",
       "6  [2, 573, \\r\\n\\r\\n                    NATHAN A ...\n",
       "7  [3, 687, \\r\\n\\r\\n                    FRANCISCO...\n",
       "8  [4, 623, \\r\\n\\r\\n                    PAUL MORR...\n",
       "9  [5, 569, \\r\\n\\r\\n                    DEREK G O..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is to convert the list into a dataframe and get a quick view of the first 10 rows using Pandas.\n",
    "df = pd.DataFrame(list_rows)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
